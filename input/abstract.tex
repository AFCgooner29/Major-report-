\begin{center}
{\Huge \bf{Abstract}\vskip 0.2in}
\end{center}
 \hrulefill \\

This is a research based project in which we have compared the processing time of various algorithms using apache spark and traditional serial programming on various data sets. As the size of the data sets changes, the difference in the processing time changes, producing some great results.\\\\
In this project we have used two systems one is the osmnx which is the traditional serial system in python. This uses simple serial programs to create the graphs. With small data sets the OSMnx creates the graphs faster.\\\\
On the other hand apache spark is used to create graph using the parrallel processing power of python program. With larger data sets the graph is created in lesser time.\\\\
GraphFrame is a spark API which takes data frame as input and created graphs so that we run parrallel programs using python.\\\\
Code related to this project is open source and shared using GitHub.


